{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#### Example 1 - WHPA\n",
    "- All the details about the example can be found in [arXiv:2105.05539](https://arxiv.org/abs/2105.05539), and the code in `skbel/examples/demo.py`.\n",
    "- It concerns a hydrogeological experiment consisting of predicting the wellhead protection area (WHPA) around a pumping well from measured breakthrough curves at said pumping well.\n",
    "- Predictor and target are generated through forward modeling from a set of hydrogeological model with different hydraulic conductivity fields (not shown).\n",
    "- The predictor is the set of breakthrough curves coming from 6 different injection wells around the pumping well (Figure 3).\n",
    "- The target is the WHPA (Figure 4).\n",
    "\n",
    "For this example, the data is already pre-processed. We are working with 400 examples of both `d` and `h` and consider one extra pair to be predicted. See details in the reference.\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"../../docs/img/data/curves.png\" background-color: white>\n",
    "</p>\n",
    "<p align=\"center\">\n",
    "  Figure 3: Predictor set. Prior in the background and test data in thick lines.\n",
    "<p align=\"center\">\n",
    "\n",
    "  <p align=\"center\">\n",
    "<img src=\"../../docs/img/whpa.png\" background-color: white>\n",
    "</p>\n",
    "<p align=\"center\">\n",
    "  Figure 4: Target set. Prior in the background (blue) and test data to predict in red.\n",
    "<p align=\"center\">"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join as jp\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
    "\n",
    "import demo_visualization as myvis\n",
    "from skbel.goggles import pca_vision, cca_vision\n",
    "\n",
    "from skbel import utils\n",
    "from skbel.learning.bel import BEL"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Building the BEL model\n",
    "In this package, a BEL model consists of a succession of Pipelines (imported from scikit-learn).\n",
    "We can define a function that returns our desired BEL model.\n",
    "- The ```X_pre_processing``` and ```Y_pre_processing``` objects are pipelines which will first scale the data for predictor and target, then apply the dimension reduction through PCA.\n",
    "\n",
    "- The ```X_post_processing``` and ```Y_post_processing``` objects are pipelines which will normalize predictor and target CV's.\n",
    "\n",
    "- Finally, the BEL model is constructed by passing as arguments all these pipelines in the `BEL` object."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def init_bel():\n",
    "    \"\"\"\n",
    "    Set all BEL pipelines. This is the blueprint of the framework.\n",
    "    \"\"\"\n",
    "    # Pipeline before CCA\n",
    "    X_pre_processing = Pipeline(\n",
    "        [\n",
    "            (\"scaler\", StandardScaler(with_mean=False)),\n",
    "            (\"pca\", PCA(n_components=50)),\n",
    "        ]\n",
    "    )\n",
    "    Y_pre_processing = Pipeline(\n",
    "        [\n",
    "            (\"scaler\", StandardScaler(with_mean=False)),\n",
    "            (\"pca\", PCA(n_components=30)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Canonical Correlation Analysis\n",
    "    cca = CCA(n_components=30)\n",
    "\n",
    "    # Pipeline after CCA\n",
    "    X_post_processing = Pipeline(\n",
    "        [(\"normalizer\", PowerTransformer(method=\"yeo-johnson\", standardize=True))]\n",
    "    )\n",
    "    Y_post_processing = Pipeline(\n",
    "        [(\"normalizer\", PowerTransformer(method=\"yeo-johnson\", standardize=True))]\n",
    "    )\n",
    "\n",
    "    # Initiate BEL object\n",
    "    bel_model = BEL(\n",
    "        X_pre_processing=X_pre_processing,\n",
    "        X_post_processing=X_post_processing,\n",
    "        Y_pre_processing=Y_pre_processing,\n",
    "        Y_post_processing=Y_post_processing,\n",
    "        cca=cca,\n",
    "    )\n",
    "\n",
    "    return bel_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_dir = jp(os.getcwd(), \"dataset\")\n",
    "# Directory in which to unload forecasts\n",
    "sub_dir = jp(os.getcwd(), \"results\")\n",
    "\n",
    "# Folders\n",
    "obj_dir = jp(sub_dir, \"obj\")  # Location to save the BEL model\n",
    "fig_data_dir = jp(sub_dir, \"data\")  # Location to save the raw data figures\n",
    "fig_pca_dir = jp(sub_dir, \"pca\")  # Location to save the PCA figures\n",
    "fig_cca_dir = jp(sub_dir, \"cca\")  # Location to save the CCA figures\n",
    "fig_pred_dir = jp(sub_dir, \"uq\")  # Location to save the prediction figures\n",
    "\n",
    "# Creates directories\n",
    "[\n",
    "    utils.dirmaker(f, erase=True)\n",
    "    for f in [\n",
    "        obj_dir,\n",
    "        fig_data_dir,\n",
    "        fig_pca_dir,\n",
    "        fig_cca_dir,\n",
    "        fig_pred_dir,\n",
    "    ]\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Set directories\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Load the dataset\n",
    "- The example dataset is saved as pandas DataFrame in `skbel/examples/dataset`.\n",
    "- An arbitrary choice has to be made on the number of PC to keep for the predictor and the target. In this case, they are set to 50 and 30, respectively.\n",
    "- The CCA operator `cca` is set to keep the maximum number of CV possible (30).\n",
    "- The variable `y_test` is the unknown target to predict. It is ignored during the training."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train = pd.read_pickle(jp(data_dir, \"X_train.pkl\"))\n",
    "X_test = pd.read_pickle(jp(data_dir, \"X_test.pkl\"))\n",
    "y_train = pd.read_pickle(jp(data_dir, \"y_train.pkl\"))\n",
    "y_test = pd.read_pickle(jp(data_dir, \"y_test.pkl\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Load dataset\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Initiate BEL model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = init_bel()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Initiate BEL model\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Set model parameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.mode = \"mvn\"  # How to compute the posterior conditional distribution\n",
    "# Save original dimensions of both predictor and target\n",
    "model.X_shape = (6, 200)  # Six curves with 200 time steps each\n",
    "model.Y_shape = (1, 100, 87)  # One matrix with 100 rows and 87 columns\n",
    "# Number of samples to be extracted from the posterior distribution\n",
    "model.n_posts = 400"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Set model parameters\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Train the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Fit BEL model\n",
    "model.fit(X=X_train, Y=y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Train the model\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Infer the posterior distribution"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# The posterior distribution is computed within the method below.\n",
    "model.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Sample for the observation\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Save the fitted BEL model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "joblib.dump(model, jp(obj_dir, \"bel.pkl\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Save the fitted BEL model\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Visualization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "myvis.plot_results(\n",
    "    model, X=X_train, X_obs=X_test, Y=y_train, Y_obs=y_test, base_dir=sub_dir, show=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Plot raw data\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pca_vision(\n",
    "    model,\n",
    "    Y_obs=y_test,\n",
    "    fig_dir=fig_pca_dir,\n",
    "    show=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Plot PCA\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cca_vision(bel=model, Y_obs=y_test, fig_dir=fig_cca_dir, show=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Plot CCA\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}